Deepfakes are the manipulation of images and videos to create otherwise genuine-seeming media that is actually fake which is a big concern for security. This project is about deepfake detection mechanism using XceptionNet for image and video type of deepfake. It uses transfer learning in an image-based detection application, by employing the ImageNet dataset and expands XceptionNet for detecting manipulations in videos. The proposed approach builds on XceptionNet and applies the feature extraction and classification for deepfakes detection method that is unified for various types of visual materials. Further improvements proposed that will be helpful in the subsequent future: the multimodal analysis â€“ here, we can add the video and audio analysis to detect deepfakes. This work is intended to resolve issues like dataset variation, computational cost, and new advances in deep fake technology to improve detection solutions.
